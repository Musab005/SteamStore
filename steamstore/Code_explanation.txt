Disabling javascript on https://store.steampowered.com/search/?filter=topsellers didn't change anything.
Hence, no need to use splash or selenium

define each data point that needs to be extracted as a scrapy field in the `items.py` file

To run the spider on your local terminal and generate a .json file for the response, run `scrapy crawl bestsellers -o test.json`
on the terminal from the parent directory of the project.

The default port for scrapyrt is 9080. You can get this port by running `scrapyrt` on the terminal.

While scrapyrt is active, to execute the spider on the web,
write: `http://127.0.0.1:9080/crawl.json?start_requests=true&spider_name=bestsellers`. The response will be the response
of your spider (json object in this case). To view it properly, enable a json extension on your browser.

To create the web app for this project, create a subfolder `Web` and further subfolders `templates` and `static`.
The templates folder will host your html file and the static folder hosts your bootstrap configurations.
Your project directory should look like this:

`    steamstore
        - steamstore
            - spiders

        - web
            - static
            - templates
                - index.html
            - app.py

        - scrapy.cfg`


To run the web app, activate scrapyrt from the terminal. Then run `python .\app.py` from the web folder. Go to the link
that is produced, and you will see the response that is generated by the return statement of the `def index` function
in the `app.py` file.



